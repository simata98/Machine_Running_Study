{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nThey were, and even if Washington might cons...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We run \"SpaceNews &amp; Views\" on our STAREACH BBS...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\n\\nNot to worry.  The Masons have been demo...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Only Brendan McKay, or maybe ARF, would come t...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Help: I am running some sample problems from O...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   0  \\nThey were, and even if Washington might cons...      10\n",
       "1   1  We run \"SpaceNews & Views\" on our STAREACH BBS...      14\n",
       "2   2  \\n\\n\\nNot to worry.  The Masons have been demo...      19\n",
       "3   3  Only Brendan McKay, or maybe ARF, would come t...      17\n",
       "4   4  Help: I am running some sample problems from O...       5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./data/뉴스그룹분류경진대회/train.csv')\n",
    "test = pd.read_csv('./data/뉴스그룹분류경진대회/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.text #training 데이터에서 문서 추출\n",
    "y = train.target #training 데이터에서 라벨 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       \\nThey were, and even if Washington might cons...\n",
       "1       We run \"SpaceNews & Views\" on our STAREACH BBS...\n",
       "2       \\n\\n\\nNot to worry.  The Masons have been demo...\n",
       "3       Only Brendan McKay, or maybe ARF, would come t...\n",
       "4       Help: I am running some sample problems from O...\n",
       "                              ...                        \n",
       "9228    \\n\\nPrecisely, why not Cuba??  Why not???  The...\n",
       "9229    Your Custom Resume On Disk!\\n \\n              ...\n",
       "9230    Throughout the years of the Israel/Arab-Palest...\n",
       "9231    Does anyone know if there are any devices avai...\n",
       "9232    \\n\\n      Give ME a break, chum.  Are you tell...\n",
       "Name: text, Length: 9233, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def clean_text(texts): \n",
    "    corpus = [] \n",
    "    for i in range(0, len(texts)): \n",
    "\n",
    "        review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"\\n\\]\\[\\>\\<]', '',texts[i]) #@%*=()/+ 와 같은 문장부호 제거\n",
    "        review = re.sub(r'\\d+','', review)#숫자 제거\n",
    "        review = review.lower() #소문자 변환\n",
    "        review = re.sub(r'\\s+', ' ', review) #extra space 제거\n",
    "        review = re.sub(r'<[^>]+>','',review) #Html tags 제거\n",
    "        review = re.sub(r'\\s+', ' ', review) #spaces 제거\n",
    "        review = re.sub(r\"^\\s+\", '', review) #space from start 제거\n",
    "        review = re.sub(r'\\s+$', '', review) #space from the end 제거\n",
    "        review = re.sub(r'_', ' ', review) #space from the end 제거\n",
    "        corpus.append(review) \n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text  target\n",
      "0        0  they were and even if washington might conside...      10\n",
      "1        1  we run spacenews views on our stareach bbs a l...      14\n",
      "2        2  not to worry the masons have been demonized an...      19\n",
      "3        3  only brendan mckay or maybe arf would come to ...      17\n",
      "4        4  help i am running some sample problems from or...       5\n",
      "...    ...                                                ...     ...\n",
      "9228  9228  precisely why not cuba why not the hatians are...      17\n",
      "9229  9229  your custom resume on disk macintosh or ibm co...       6\n",
      "9230  9230  throughout the years of the israelarabpalestin...      17\n",
      "9231  9231  does anyone know if there are any devices avai...       4\n",
      "9232  9232  give me a break chum are you telling me that c...      18\n",
      "\n",
      "[9233 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "temp = clean_text(train['text'])\n",
    "train['text'] = temp\n",
    "print(train)\n",
    "\n",
    "temp = clean_text(test['text'])\n",
    "test['text'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, nice to meet you. What's your name? Have a nice day! See you soon.\" # 예시 문장을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from os import path\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 토큰화 결과 ==> ['Hello, nice to meet you.', \"What's your name?\", 'Have a nice day!', 'See you soon.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "print('문장 토큰화 결과 ==>',sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화 결과 ==> ['Hello', ',', 'nice', 'to', 'meet', 'you', '.', 'What', \"'s\", 'your', 'name', '?', 'Have', 'a', 'nice', 'day', '!', 'See', 'you', 'soon', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print('단어 토큰화 결과 ==>', word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "      <td>10</td>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "      <td>14</td>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "      <td>19</td>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "      <td>17</td>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "      <td>5</td>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target  \\\n",
       "0   0  they were and even if washington might conside...      10   \n",
       "1   1  we run spacenews views on our stareach bbs a l...      14   \n",
       "2   2  not to worry the masons have been demonized an...      19   \n",
       "3   3  only brendan mckay or maybe arf would come to ...      17   \n",
       "4   4  help i am running some sample problems from or...       5   \n",
       "\n",
       "                                      tokenized_stem  \n",
       "0  they were and even if washington might conside...  \n",
       "1  we run spacenews views on our stareach bbs a l...  \n",
       "2  not to worry the masons have been demonized an...  \n",
       "3  only brendan mckay or maybe arf would come to ...  \n",
       "4  help i am running some sample problems from or...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = [] # 데이터프레임의 한 컬럼으로 추가할 리스트\n",
    "for sentence in train['text']: # 전처리된 리뷰들을 하나씩 꺼내옵니다\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokenize = \" \".join(tokens) # tokens라는 리스트 안의 형태소들을 띄어쓰기로 분리된 하나의 문자열로 join시켜줍니다.\n",
    "    tokenized.append(tokenize) # 형태소 단위로 띄어쓰기된 문자열을 최종 리스트에 추가해줍니다\n",
    "train[\"tokenized_stem\"] = pd.DataFrame(tokenized) # 리스트를 데이터프레임으로 변환해 tokenized_stem라는 컬럼명으로 추가해줍니다.\n",
    "\n",
    "train.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 품사 태깅\n",
    "주어진 텍스트를 형태소 단위로 나눈 뒤, 각 형태소에 해당 품사를 태깅하여 리스트화  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('help', 'NN'), ('i', 'VB'), ('am', 'VBP'), ('running', 'VBG'), ('some', 'DT'), ('sample', 'NN'), ('problems', 'NNS'), ('from', 'IN'), ('oreilly', 'RB'), ('volume', 'NN'), ('xt', 'JJ'), ('intrisics', 'NNS'), ('programming', 'VBG'), ('manual', 'JJ'), ('chapter', 'NN'), ('popupdialog', 'NN'), ('boxes', 'NNS'), ('and', 'CC'), ('so', 'RB'), ('onin', 'JJ'), ('example', 'NN'), ('page', 'NN'), ('creating', 'VBG'), ('a', 'DT'), ('popup', 'NN'), ('dialog', 'NN'), ('boxthe', 'JJ'), ('application', 'NN'), ('creates', 'VBZ'), ('window', 'VBP'), ('with', 'IN'), ('a', 'DT'), ('button', 'NN'), ('quit', 'NN'), ('and', 'CC'), ('press', 'NN'), ('methe', 'VBP'), ('button', 'NN'), ('press', 'NN'), ('me', 'PRP'), ('pops', 'VBZ'), ('up', 'RP'), ('a', 'DT'), ('dialog', 'NN'), ('box', 'IN'), ('the', 'DT'), ('strange', 'JJ'), ('feature', 'NN'), ('ofthis', 'JJ'), ('program', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('it', 'PRP'), ('always', 'RB'), ('pops', 'VBZ'), ('up', 'RP'), ('the', 'DT'), ('dialog', 'NN'), ('box', 'NN'), ('much', 'JJ'), ('faster', 'RBR'), ('thefirst', 'JJ'), ('time', 'NN'), ('if', 'IN'), ('i', 'JJ'), ('try', 'VBP'), ('to', 'TO'), ('pop', 'VB'), ('it', 'PRP'), ('up', 'RP'), ('a', 'DT'), ('nd', 'JJ'), ('time', 'NN'), ('rd', 'VB'), ('th', 'JJ'), ('time', 'NN'), ('it', 'PRP'), ('is', 'VBZ'), ('much', 'JJ'), ('slowerhas', 'IN'), ('anyone', 'NN'), ('any', 'DT'), ('experience', 'NN'), ('with', 'IN'), ('these', 'DT'), ('sample', 'JJ'), ('programs', 'NNS'), ('or', 'CC'), ('why', 'WRB'), ('i', 'JJ'), ('getthis', 'VBP'), ('behaviour', 'JJ'), ('fast', 'JJ'), ('response', 'NN'), ('time', 'NN'), ('for', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('time', 'NN'), ('but', 'CC'), ('slow', 'JJ'), ('responsetime', 'NN'), ('from', 'IN'), ('nd', 'JJ'), ('time', 'NN'), ('onwards', 'IN'), ('anyone', 'NN'), ('can', 'MD'), ('give', 'VB'), ('me', 'PRP'), ('some', 'DT'), ('ideas', 'NNS'), ('on', 'IN'), ('how', 'WRB'), ('to', 'TO'), ('program', 'NN'), ('popups', 'NNS'), ('so', 'RB'), ('that', 'IN'), ('each', 'DT'), ('timethey', 'NN'), ('popup', 'VBP'), ('in', 'IN'), ('reasonable', 'JJ'), ('fast', 'JJ'), ('response', 'NN'), ('time', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# pos_tag()의 입력값으로는 단어의 리스트가 들어가야 한다.\n",
    "print(nltk.pos_tag(nltk.word_tokenize(train['text'][4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_stem</th>\n",
       "      <th>main_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "      <td>10</td>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "      <td>were even washington consider patty bust id tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "      <td>14</td>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "      <td>run spacenews views stareach bbs localoperatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "      <td>19</td>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "      <td>not worry masons have been demonized harrassed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "      <td>17</td>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "      <td>only brendan mckay maybe arf come rescue nazir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "      <td>5</td>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "      <td>help i am running sample problems oreilly volu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target  \\\n",
       "0   0  they were and even if washington might conside...      10   \n",
       "1   1  we run spacenews views on our stareach bbs a l...      14   \n",
       "2   2  not to worry the masons have been demonized an...      19   \n",
       "3   3  only brendan mckay or maybe arf would come to ...      17   \n",
       "4   4  help i am running some sample problems from or...       5   \n",
       "\n",
       "                                      tokenized_stem  \\\n",
       "0  they were and even if washington might conside...   \n",
       "1  we run spacenews views on our stareach bbs a l...   \n",
       "2  not to worry the masons have been demonized an...   \n",
       "3  only brendan mckay or maybe arf would come to ...   \n",
       "4  help i am running some sample problems from or...   \n",
       "\n",
       "                                            main_pos  \n",
       "0  were even washington consider patty bust id tr...  \n",
       "1  run spacenews views stareach bbs localoperatio...  \n",
       "2  not worry masons have been demonized harrassed...  \n",
       "3  only brendan mckay maybe arf come rescue nazir...  \n",
       "4  help i am running sample problems oreilly volu...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def postagging(dataframe):\n",
    "    main_pos = [] # 데이터프레임의 새 컬럼이 될 리스트\n",
    "    for sentence in dataframe['text']: # 리뷰들을 하나씩 가져옵니다\n",
    "        pos = nltk.pos_tag(nltk.word_tokenize(sentence)) # 형태소 분석을 진행하고 해당 리스트를 pos라는 변수로 받습니다\n",
    "        main_words = [word_pos[0] for word_pos in pos if word_pos[1] in ('JJ', 'JJR', 'JJS', #형용사\n",
    "                                                                        'NN', 'NNS', 'NNP', 'NNPS', #명사\n",
    "                                                                        'RB', 'RBR', 'RBBS', #부사\n",
    "                                                                        'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ' #동사\n",
    "                                                                        )] # 가져오고자 하는 품사에 해당하면 해당 형태소를 main_words 리스트에 추가합니다.\n",
    "        main_words_str = \" \".join(main_words) # main_words 리스트 안의 형태소들을 띄어쓰기로 분리된 하나의 문자열로 join시켜줍니다.\n",
    "        main_pos.append(main_words_str) # 선택한 형태소들로 이루어진 문자열을 최종 리스트에 추가해줍니다\n",
    "        dataframe[\"main_pos\"] = pd.DataFrame(main_pos) # 리스트를 데이터프레임으로 변환해 main_pos라는 컬럼명으로 추가해줍니다.\n",
    "\n",
    "postagging(train)\n",
    "postagging(test) ## test셋도 똑같이 품사태깅을 적용해줍니다.\n",
    "train.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = train.copy()\n",
    "train, val = train_test_split(data)\n",
    "train.reset_index(inplace=True) # 전처리 과정에서 데이터가 뒤섞이지 않도록 인덱스를 초기화해주었습니다.\n",
    "val.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 셋 모양 : (6924, 6)\n",
      "val 데이터 셋 모양 : (2309, 6)\n"
     ]
    }
   ],
   "source": [
    "print( 'train 데이터 셋 모양 :', train.shape)\n",
    "print( 'val 데이터 셋 모양 :', val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.main_pos #training 데이터에서 문서 추출\n",
    "y_train = train.target #training 데이터에서 라벨 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer() #countvectorizer 생성\n",
    "vectorizer.fit(X_train) # countvectorizer 학습\n",
    "X_train_vec = vectorizer.transform(X_train) # transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #모델 불러오기\n",
    "model = LogisticRegression(max_iter=500) #객체에 모델 할당\n",
    "model.fit(X_train_vec, y_train) #모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val.main_pos #validation 데이터에서 전처리된 문서 추출\n",
    "y_val = val.target #validation 데이터에서 라벨 추출\n",
    "\n",
    "X_val_vec = vectorizer.transform(X_val) # train셋으로 fit한 벡터라이저 이용해 transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 18  5 ... 14 13 14]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val_vec)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 의 예측 정확도는 0.595\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Logistic Regression 의 예측 정확도는', round(metrics.accuracy_score(y_val, y_pred),3)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "TF(단어 빈도, term frequency) : 특정한 단어가 문서 내에 얼마나 자주 등장하는지  \n",
    "IDF(역문서 빈도, inverse document frequency) : 단어 자체가 문서군 내에서 자주 사용하여 얼마나 그 단어가 흔하게 등장하는지  \n",
    "\n",
    "즉, 특정 문서 내에서 단어 빈도가 높을 수록, 그리고 전체 문서들 중 그 단어를 포함한 문서가 적을 수록 TF-IDF값이 높아짐  \n",
    "\n",
    "TF-IDF는 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업,\n",
    "문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 & 테스트 데이터 Text의 TfidfVectorizer Shape: (6924, 638605) (2309, 638605)\n",
      "TF-IDF Logistic Regression 의 예측 정확도는 0.719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train = train.main_pos #training 데이터에서 문서 추출\n",
    "y_train = train.target #training 데이터에서 라벨 추출\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환. \n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2), max_df=300)\n",
    "tfidf_vect.fit(X_train)\n",
    "\n",
    "X_val = val.main_pos #validation 데이터에서 전처리된 문서 추출\n",
    "y_val = val.target #validation 데이터에서 라벨 추출\n",
    "\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_val_tfidf_vect = tfidf_vect.transform(X_val) # train셋으로 fit한 벡터라이저 이용해 transform\n",
    "print('학습 & 테스트 데이터 Text의 TfidfVectorizer Shape:',X_train_tfidf_vect.shape, X_val_tfidf_vect.shape)\n",
    "\n",
    "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
    "lr_clf = LogisticRegression(solver='liblinear', C = 10) \n",
    "lr_clf.fit(X_train_tfidf_vect , y_train)\n",
    "pred = lr_clf.predict(X_val_tfidf_vect)\n",
    "print('TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}'.format(metrics.accuracy_score(y_val ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, solver='liblinear')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data.main_pos #전체 training 데이터에서 문서 추출\n",
    "y_train = data.target #전체 training 데이터에서 라벨 추출\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환. \n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2), max_df=300)\n",
    "tfidf_vect.fit(X_train)\n",
    "\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "\n",
    "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
    "lr_clf = LogisticRegression(solver='liblinear', C = 10) \n",
    "lr_clf.fit(X_train_tfidf_vect , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 16 11 ...  4  1 12]\n"
     ]
    }
   ],
   "source": [
    "X_test = test.main_pos\n",
    "X_test_vec = tfidf_vect.transform(X_test)\n",
    "pred_test = lr_clf.predict(X_test_vec)\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   1       0\n",
       "2   2       0\n",
       "3   3       0\n",
       "4   4       0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('data/뉴스그룹분류경진대회/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>9228</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>9229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>9230</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>9231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>9232</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target\n",
       "0        0       3\n",
       "1        1      16\n",
       "2        2      11\n",
       "3        3       8\n",
       "4        4      13\n",
       "...    ...     ...\n",
       "9228  9228      16\n",
       "9229  9229       1\n",
       "9230  9230       4\n",
       "9231  9231       1\n",
       "9232  9232      12\n",
       "\n",
       "[9233 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'] = pred_test\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_baseline2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15f10dcb598d47efbe810bd2c785e8a886734184bcff6212faabf44ef684ce9a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('personal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
